# -*- coding: utf-8 -*-
"""gradcamclassdiaper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gwdZX_sim_DC7IprTaiyWa0wgBnFOQMT
"""

"""To run in Google Collab
from google.colab import drive
drive.flush_and_unmount()
drive.mount('/content/drive', force_remount=True)

import os
os.chdir('./drive/MyDrive/')
"""

#import required libraries
import tensorflow as tf
import glob
import os
from tensorflow.keras.models import load_model, save_model, Model
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv3D, MaxPool3D, ZeroPadding3D
from tensorflow.keras.optimizers import SGD, Adam
import pandas as pd
import numpy as np
import matplotlib
import cv2
from skimage.transform import resize
import scipy.ndimage
import matplotlib.pyplot as plt
import sys
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential

"""Reading all videos and their corresponding labels from all classes"""
#30 second video of dimension 250x150 is fed
seq_len = 30
img_height = 250 
img_width = 150 

#number of classes the product can be categorized into
classes = ["Poor", "Fair", "Good", "Very Good", "Excellent"]

#  Creating frames from videos
def frames_extraction(video_path):
    frames_list = []
     
    vidObj = cv2.VideoCapture(video_path)
    count = 1 
    while count <= seq_len:          
        success, image = vidObj.read()
        if success:
            image = cv2.resize(image, (img_height, img_width))
            frames_list.append(image)
            count += 1
        else:
            print("Defected frame")
            break
    frames_list = np.array(frames_list, dtype=np.float32)
    return frames_list
 
def create_data(input_dir):
    X = []
    Y = []
     
    classes_list = os.listdir(input_dir)
     
    for c in sorted(classes_list):
        print(c)
        files_list = os.listdir(os.path.join(input_dir, c))
        for f in files_list:
            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))
            x = frames[:, 15:140, 25:237, :]     #16 diapers
            start_frame = 0           
            # center crop
            x = frames[start_frame:31, 15:140, 25:237, :] #16 diapers
            y = [0]*len(classes)
            y[classes.index(c)] = 1
            X.append(x)
            Y.append(y)
    X = np.asarray(X)
    Y = np.asarray(Y)
    return X, Y

data_dir = "/content/drive/MyDrive/GradCAMClassDiaper/train/"
X, Y = create_data(data_dir)

#X consists of all videos and Y consists of all associated labels
print(X.shape)
print(Y.shape)

"""Training - Setting up the network architecture to begin training"""

import datetime

X_train, y_train = X, Y

model = Sequential()
input_shape=(30, 115, 200, 3) # l, h, w, c settings for stretch
    
model.add(Conv3D(64, 3, activation='relu',
                        padding='same', name='conv1',
                        input_shape=input_shape))
model.add(MaxPool3D(pool_size=(1, 2, 2), strides=(1, 2, 2),
                       padding='valid', name='pool1'))
# 2nd layer group
model.add(Conv3D(128, 3, activation='relu',
                        padding='same', name='conv2'))
model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid', name='pool2'))
# 3rd layer group
model.add(Conv3D(256, 3, activation='relu',
                        padding='same', name='conv3a'))
model.add(Conv3D(256, 3, activation='relu',
                        padding='same', name='conv3b'))
model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid', name='pool3'))
# 4th layer group
model.add(Conv3D(512, 3, activation='relu',
                        padding='same', name='conv4a'))
model.add(Conv3D(512, 3, activation='relu',
                        padding='same', name='conv4b'))
model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid', name='pool4'))
# 5th layer group
model.add(Conv3D(512, 3, activation='relu',
                        padding='same', name='conv5a'))
model.add(Conv3D(512, 3, activation='relu',
                        padding='same', name='conv5b'))
model.add(ZeroPadding3D(padding=(0, 1, 1), name='zeropad5'))
model.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid', name='pool5'))
model.add(Flatten())
# FC layers group
model.add(Dense(4096, activation='relu', name='fc6'))
model.add(Dropout(.5))
model.add(Dense(4096, activation='relu', name='fc7'))
model.add(Dropout(.5))
model.add(Dense(5, activation='softmax', name='fc8'))
 
model.summary()

#compile the model with an optimizer and setup metrics to evaluate the model performance
model.compile(optimizer=SGD(learning_rate=0.0005),loss='mean_squared_error',metrics=['mean_squared_error'])

#Used when the model does not converge
# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
#     monitor='mean_squared_error',
#     factor=0.8,
#     patience=8,
#     verbose=1,
#     mode="auto",
#     min_delta=2,
#     cooldown=0,
#     min_lr=0
# )

#train the model
history = model.fit(x = X_train, y = y_train, epochs=75, batch_size = 4, shuffle=True, verbose=1)

#save the trained model in the local storage
model.save("/content/drive/MyDrive/GradCamClassDiaper/FinalModels/GradCamClassDiaper.hdf5")


"""Testing - Feed the test video to the model"""

seq_len = 30
img_height = 250 
img_width = 150 

classes = ["Poor", "Fair", "Good", "Very Good", "Excellent"]
labels = ["Poor", "Fair", "Good", "Very Good", "Excellent"]

#  Creating frames from videos
def frames_extraction(video_path):
    frames_list = []
     
    vidObj = cv2.VideoCapture(video_path)
    count = 1 
    while count <= seq_len:          
        success, image = vidObj.read() 
        if success:
            image = cv2.resize(image, (img_height, img_width))
            frames_list.append(image)
            count += 1
        else:
            print("Defected frame")
            break
    frames_list = np.array(frames_list, dtype=np.float32)
    return frames_list
 
def create_data(input_dir):
    X = []
    
    classes_list = os.listdir(input_dir)
     
    for c in sorted(classes_list):
        print(c)
        files_list = os.listdir(os.path.join(input_dir, c))
        print(files_list)
        for f in files_list:
            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))
            x = frames[:, 15:140, 25:237, :] 
            start_frame = 0             
            # center crop
            x = frames[start_frame:31, 15:140, 25:237, :] 
            y = [0]*len(classes)
            y[classes.index(c)] = 1
            X.append(x)
    X = np.asarray(X)
    return X

data_dir = "/content/drive/MyDrive/GradCAMClassDiaper/test/"
X = create_data(data_dir)

print(X.shape)

#individual classifier prediction
prediction = model.predict(X)
top_inds = prediction[0].argsort()[::-1][:5]
for i in top_inds:
    print('{1}: {0:.5f}'.format(prediction[0][i], labels[i]))
print(prediction)


"""Generating Activation Maps"""

from keras.layers.core import Lambda
import keras.backend as K

def target_category_loss(x, category_index, nb_classes):
    return tf.multiply(x, K.one_hot([category_index], nb_classes))

def target_category_loss_output_shape(input_shape):
    return input_shape

def normalize(x):
    # utility function to normalize a tensor by its L2 norm
    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)

labels = ["Poor", "Fair", "Good", "Very Good", "Excellent"]
predicted_class = np.argmax(prediction)
print(predicted_class)
print(prediction[0][predicted_class], labels[predicted_class])

nb_classes = len(labels)
target_layer = lambda x: target_category_loss(x, predicted_class, nb_classes)
model.add(Lambda(target_layer, output_shape = target_category_loss_output_shape))
model.summary()
temp_label = np.zeros(prediction.shape)
temp_label[0][int(np.argmax(prediction))] = 1.0
print(temp_label)
loss = K.sum(model.layers[-1].output*(temp_label))
print(model.layers[-1].output)
print(loss)

for i in range(14):
    ###########Choose a conv layer to generate saliency maps##########
    if model.layers[i].name == "conv3a":
        conv_output = model.layers[i].output
        break
print(conv_output)

tf.compat.v1.disable_eager_execution()

grads = K.gradients(loss, conv_output)[0]
#grads = tf.math.l2_normalize(grads, axis=None, epsilon=1e-5, name=None)

first_derivative = tf.exp(loss)*grads 
print(first_derivative[0])
print(tf.exp(loss))
        
#second_derivative
second_derivative = tf.exp(loss)*grads*grads 
print(second_derivative[0])

#triple_derivative
triple_derivative = tf.exp(loss)*grads*grads*grads
print(triple_derivative[0])

gradient_function = K.function([model.layers[0].input, K.learning_phase()], [conv_output, grads, first_derivative, second_derivative, triple_derivative])
grads_output, grads_val, conv_first_grad, conv_second_grad, conv_third_grad = gradient_function([X, 0])
grads_output, grads_val, conv_first_grad, conv_second_grad, conv_third_grad = grads_output[0, :, :], grads_val[0, :, :, :], conv_first_grad[0, :, :, :], conv_second_grad[0, :, :, :], conv_third_grad[0, :, :, :]
print(grads_output.shape, np.max(grads_output), np.min(grads_output))
print(grads_val.shape, np.max(grads_val), np.min(grads_val))
print(conv_first_grad.shape,np.max(conv_first_grad), np.min(conv_first_grad))
print(conv_second_grad.shape,np.max(conv_second_grad), np.min(conv_second_grad))
print(conv_third_grad.shape,np.max(conv_third_grad), np.min(conv_third_grad))

global_sum = np.sum(conv_third_grad.reshape((-1,256)), axis=0)
#print global_sum
        
alpha_num = conv_second_grad
alpha_denom = conv_second_grad*2.0 + conv_third_grad*global_sum.reshape((-1,))
alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))
alphas = alpha_num/alpha_denom

weights = np.maximum(conv_first_grad, 0.0)
#normalizing the alphas
alphas_thresholding = np.where(weights, alphas, 0.0)

alpha_normalization_constant = np.sum(np.sum(np.sum(alphas_thresholding, axis=0),axis=0),axis=0)
alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))

alphas /= alpha_normalization_constant_processed.reshape((1,1,1,256))
#print alphas

deep_linearization_weights = np.sum((weights*alphas).reshape((-1,256)),axis=0)
#print deep_linearization_weights
grad_CAM_map = np.sum(deep_linearization_weights*grads_output, axis=3)
print(np.max(grad_CAM_map),np.min(grad_CAM_map))

grad_CAM_map = scipy.ndimage.zoom(grad_CAM_map, (2, 4, 4))
print(np.max(grad_CAM_map),np.min(grad_CAM_map))
# Passing through ReLU
vid_cam = np.maximum(grad_CAM_map, 0)
vid_heatmap = vid_cam / np.max(vid_cam) # scale 0 to 1.0  
print(vid_heatmap.shape)

"""Store the activation maps obtained"""

for i in range(vid_heatmap.shape[0]):
  plt.imsave("/content/drive/MyDrive/GradCAMClassDiaper/Output/PBC/Heatmaps/image{}.jpg".format(i), vid_heatmap[i], cmap='jet')

