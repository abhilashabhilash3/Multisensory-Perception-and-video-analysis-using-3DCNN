# -*- coding: utf-8 -*-
"""shallow_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ki2lY0kEgLmGLH4pUlR_-494j1yom5t5
"""

"""To run in Google Collab
from google.colab import drive
drive.flush_and_unmount()
drive.mount('/content/drive', force_remount=True)

import os
os.chdir('./drive/MyDrive/')
"""

#import required libraries
import tensorflow as tf
import glob
import os
from tensorflow.keras.models import load_model, save_model, Model
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv3D, MaxPool3D, ZeroPadding3D
from tensorflow.keras.optimizers import SGD, Adam
import pandas as pd
import numpy as np
import matplotlib
import cv2
from skimage.transform import resize
import scipy.ndimage
import matplotlib.pyplot as plt
import sys
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential
from numpy import loadtxt
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras.optimizers import SGD, Adam
import tensorflow as tf
import numpy as np
from io import StringIO

"""Load all 3 pre-trained models(Back Waist, Front Waist, Leg Cuffs)and save their weights"""
model1 = tf.keras.models.load_model('/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaper.hdf5')
model2 = tf.keras.models.load_model('/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaperLCS.hdf5')
model3 = tf.keras.models.load_model('/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaperFWS.hdf5')

model1.save_weights("/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaper_weights.hdf5")
model2.save_weights("/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaperLCS_weights.hdf5")
model3.save_weights("/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaperFWS_weights.hdf5")

"""Modify all 3 models to combine them later"""
#first model
model1 = Sequential()
input_shape=(30, 112, 212, 3) # l, h, w, c settings for stretch
    
model1.add(Conv3D(64, 3, activation='relu',
                        padding='same',
                        input_shape=input_shape))
model1.add(MaxPool3D(pool_size=(1, 2, 2), strides=(1, 2, 2),
                       padding='valid'))
# 2nd layer group
model1.add(Conv3D(128, 3, activation='relu',
                        padding='same'))
model1.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 3rd layer group
model1.add(Conv3D(256, 3, activation='relu',
                        padding='same'))
model1.add(Conv3D(256, 3, activation='relu',
                        padding='same'))
model1.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 4th layer group
model1.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model1.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model1.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 5th layer group
model1.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model1.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model1.add(ZeroPadding3D(padding=(0, 1, 1)))
model1.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
model1.add(Flatten())
# FC layers group
model1.add(Dense(4096, activation='relu'))
model1.add(Dropout(.5))
model1.add(Dense(4096, activation='relu'))
model1.add(Dropout(.5))
model1.add(Dense(5, activation='softmax'))

#second model
model2 = Sequential()
input_shape=(30, 112, 212, 3) # l, h, w, c settings for stretch
    
model2.add(Conv3D(64, 3, activation='relu',
                        padding='same',
                        input_shape=input_shape))
model2.add(MaxPool3D(pool_size=(1, 2, 2), strides=(1, 2, 2),
                       padding='valid'))
# 2nd layer group
model2.add(Conv3D(128, 3, activation='relu',
                        padding='same'))
model2.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 3rd layer group
model2.add(Conv3D(256, 3, activation='relu',
                        padding='same'))
model2.add(Conv3D(256, 3, activation='relu',
                        padding='same'))
model2.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 4th layer group
model2.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model2.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model2.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 5th layer group
model2.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model2.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model2.add(ZeroPadding3D(padding=(0, 1, 1)))
model2.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
model2.add(Flatten())
# FC layers group
model2.add(Dense(4096, activation='relu'))
model2.add(Dropout(.5))
model2.add(Dense(4096, activation='relu'))
model2.add(Dropout(.5))
model2.add(Dense(5, activation='softmax'))

#third model
model3 = Sequential()
input_shape=(30, 112, 212, 3) # l, h, w, c settings for stretch
    
model3.add(Conv3D(64, 3, activation='relu',
                        padding='same',
                        input_shape=input_shape))
model3.add(MaxPool3D(pool_size=(1, 2, 2), strides=(1, 2, 2),
                       padding='valid'))
# 2nd layer group
model3.add(Conv3D(128, 3, activation='relu',
                        padding='same'))
model3.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 3rd layer group
model3.add(Conv3D(256, 3, activation='relu',
                        padding='same'))
model3.add(Conv3D(256, 3, activation='relu',
                        padding='same'))
model3.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 4th layer group
model3.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model3.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model3.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
# 5th layer group
model3.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model3.add(Conv3D(512, 3, activation='relu',
                        padding='same'))
model3.add(ZeroPadding3D(padding=(0, 1, 1)))
model3.add(MaxPool3D(pool_size=(2, 2, 2), strides=(2, 2, 2),
                       padding='valid'))
model3.add(Flatten())
# FC layers group
model3.add(Dense(4096, activation='relu'))
model3.add(Dropout(.5))
model3.add(Dense(4096, activation='relu'))
model3.add(Dropout(.5))
model3.add(Dense(5, activation='softmax'))

#Loading the weights back to the reconfigured models
model1.load_weights("/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaper_weights.hdf5")
model2.load_weights("/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaperLCS_weights.hdf5")
model3.load_weights("/content/drive/MyDrive/GradCamClassDiaper/NewDatasetModels/gradcamclassdiaperFWS_weights.hdf5")

"""Combine the 3 reconfigured models into a fourth model called concatenated"""
groundtruthlabels1 = tf.constant([100.0, 75.0, 50.0, 25.0, 0.0])
groundtruthlabels1 = tf.reshape(groundtruthlabels1, (1, 5))
print(groundtruthlabels1.shape)

groundtruthlabels2 = tf.constant([100.0, 75.0, 50.0, 25.0, 0.0])
groundtruthlabels2 = tf.reshape(groundtruthlabels2, (1, 5))
print(groundtruthlabels2.shape)

groundtruthlabels3 = tf.constant([100.0, 75.0, 50.0, 25.0, 0.0])
groundtruthlabels3 = tf.reshape(groundtruthlabels3, (1, 5))
print(groundtruthlabels3.shape)

print(model1.output.shape)
dotted1 = tf.keras.layers.Dot(axes=1)([model1.output, groundtruthlabels1])
dotted2 = tf.keras.layers.Dot(axes=1)([model2.output, groundtruthlabels2])
dotted3 = tf.keras.layers.Dot(axes=1)([model3.output, groundtruthlabels3])
dotted1.shape
dotted2.shape
dotted3.shape

concatenated = tf.keras.layers.Concatenate()([dotted1, dotted2, dotted3])
concatenated.shape

#load the trained shallow network model from local storage
model4 = tf.keras.models.load_model('/content/drive/MyDrive/GradCamClassDiaper/Models/shallow_network_Premiumness_4_Classes.hdf5')

"""Predict the overall comfort fit score by feeding as input Back Waist, Front Waist and Leg Cuff Videos of 1 product"""

#30 second video of dimension 250x150 is fed
seq_len = 30
img_height = 250 
img_width = 150 

#number of classes the product can be categorized into
classes = ["Poor", "Fair", "Good", "Very Good", "Excellent"]
labels = ["Poor", "Fair", "Good", "Very Good", "Excellent"]

"""First input is a Back Waist Stretch video"""
#  Creating frames from videos
def frames_extraction(video_path):
    frames_list = []
     
    vidObj = cv2.VideoCapture(video_path)
    count = 1 
    while count <= seq_len:          
        success, image = vidObj.read() 
        if success:
            image = cv2.resize(image, (img_height, img_width))
            frames_list.append(image)
            count += 1
        else:
            print("Defected frame")
            break
    frames_list = np.array(frames_list, dtype=np.float32)
    return frames_list

def create_data(input_dir):
    X = []
    #Y = []
     
    classes_list = os.listdir(input_dir)
     
    for c in sorted(classes_list):
        print(c)
        files_list = os.listdir(os.path.join(input_dir, c))
        print(files_list)
        for f in files_list:
            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))
            # np.append(X, frames)
            x = frames[:, 3:115, 25:237, :]
            start_frame = 0
            # X = frames[start_frame:17, :, :, :]               
            # center crop
            x = frames[start_frame:31, 3:115, 25:237, :] # (l, h, w, c)
            y = [0]*len(classes)
            y[classes.index(c)] = 1 
            #y = classes_dict[c]
            X.append(x)
            #Y.append(y) 
        # X = np.expand_dims(X, axis=0)
        # X = X[len(f), :, :, :, :]
    # cv2.imwrite("/content/original-image.jpg", X[0])
    X = np.asarray(X)
    #Y = np.asarray(Y)
    return X

data_dir1 = "/content/drive/MyDrive/GradCamDiaper/test/BWS/"
X1 = create_data(data_dir1)

"""Second input X2 is a Front Waist Stretch video"""
#  Creating frames from videos
def frames_extraction(video_path):
    frames_list = []
     
    vidObj = cv2.VideoCapture(video_path)
    count = 1 
    while count <= seq_len:          
        success, image = vidObj.read() 
        if success:
            image = cv2.resize(image, (img_height, img_width))
            frames_list.append(image)
            count += 1
        else:
            print("Defected frame")
            break
    frames_list = np.array(frames_list, dtype=np.float32)
    return frames_list

def create_data(input_dir):
    X = []
    #Y = []
     
    classes_list = os.listdir(input_dir)
     
    for c in sorted(classes_list):
        print(c)
        files_list = os.listdir(os.path.join(input_dir, c))
        print(files_list)
        for f in files_list:
            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))
            # np.append(X, frames)
            x = frames[:, 3:115, 25:237, :]
            start_frame = 0
            # X = frames[start_frame:17, :, :, :]               
            # center crop
            x = frames[start_frame:31, 3:115, 25:237, :] # (l, h, w, c)
            y = [0]*len(classes)
            y[classes.index(c)] = 1 
            #y = classes_dict[c]
            X.append(x)
            #Y.append(y) 
        # X = np.expand_dims(X, axis=0)
        # X = X[len(f), :, :, :, :]
    # cv2.imwrite("/content/original-image.jpg", X[0])
    X = np.asarray(X)
    #Y = np.asarray(Y)
    return X
data_dir2 = "/content/drive/MyDrive/GradCamDiaper/test/FWS/"
X2 = create_data(data_dir2)

"""Third input X3 is a Leg Cuff Stretch video"""
#  Creating frames from videos
def frames_extraction(video_path):
    frames_list = []
     
    vidObj = cv2.VideoCapture(video_path)
    count = 1 
    while count <= seq_len:          
        success, image = vidObj.read() 
        if success:
            image = cv2.resize(image, (img_height, img_width))
            frames_list.append(image)
            count += 1
        else:
            print("Defected frame")
            break
    frames_list = np.array(frames_list, dtype=np.float32)
    return frames_list

def create_data(input_dir):
    X = []
    #Y = []
     
    classes_list = os.listdir(input_dir)
     
    for c in sorted(classes_list):
        print(c)
        files_list = os.listdir(os.path.join(input_dir, c))
        print(files_list)
        for f in files_list:
            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))
            # np.append(X, frames)
            x = frames[:, 3:115, 25:237, :]
            start_frame = 0
            # X = frames[start_frame:17, :, :, :]               
            # center crop
            x = frames[start_frame:31, 3:115, 25:237, :] # (l, h, w, c)
            y = [0]*len(classes)
            y[classes.index(c)] = 1 
            #y = classes_dict[c]
            X.append(x)
            #Y.append(y) 
        # X = np.expand_dims(X, axis=0)
        # X = X[len(f), :, :, :, :]
    # cv2.imwrite("/content/original-image.jpg", X[0])
    X = np.asarray(X)
    #Y = np.asarray(Y)
    return X
data_dir3 = "/content/drive/MyDrive/GradCamDiaper/test/LCS/"
X3 = create_data(data_dir3)

print(X1.shape)
print(X2.shape)
print(X3.shape)

#final testing
finaloutput = model4(concatenated)
model5 = tf.keras.models.Model(inputs=[model1.inputs, model2.inputs, model3.inputs], outputs=finaloutput)
model5.predict([X1, X2, X3])

"""Importance of a feature in making a prediction""" 
#print the model weights and bisases
print(model4.weights[5].shape) #bias3
print(model4.weights[4].shape) #weights3
print(model4.weights[3].shape) #bias2
print(model4.weights[2].shape) #weights2
print(model4.weights[1].shape) #bias1
print(model4.weights[0].shape) #weights1

#weights2 tells us that the larger the value of weight of one feature, the higher is its importance
weights1= tf.linalg.matmul(model4.weights[0], model4.weights[2])
weights2 = tf.linalg.matmul(weights1, model4.weights[4])
print(weights2)